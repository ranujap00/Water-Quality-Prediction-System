{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Water Quality Prediction.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of 500000 rows\n",
    "df = df.sample(n=300000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                         0\n",
       "pH                         9709\n",
       "Iron                       3339\n",
       "Nitrate                    8910\n",
       "Chloride                  14696\n",
       "Lead                       2217\n",
       "Zinc                      13279\n",
       "Color                       463\n",
       "Turbidity                  4107\n",
       "Fluoride                  15795\n",
       "Copper                    16710\n",
       "Odor                      15004\n",
       "Sulfate                   16266\n",
       "Conductivity              13797\n",
       "Chlorine                   4720\n",
       "Manganese                  9140\n",
       "Total Dissolved Solids      133\n",
       "Source                     7381\n",
       "Water Temperature         14135\n",
       "Air Temperature            2527\n",
       "Month                      7999\n",
       "Day                        8297\n",
       "Time of Day                9739\n",
       "Potability                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "if duplicate_rows.count().sum() == 0:\n",
    "   print(\"No duplicate rows\")\n",
    "else:\n",
    "   print(\"Duplicate rows are present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove month and index columns\n",
    "df = df.drop(['Month', 'Index'], axis=1) # axis=1 indicates we are dropping a column, not a row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values in color and source columns\n",
    "df = df.dropna(subset=[\"Color\", \"Source\"])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Nitrate</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Color</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Fluoride</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Odor</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Chlorine</th>\n",
       "      <th>Manganese</th>\n",
       "      <th>Total Dissolved Solids</th>\n",
       "      <th>Water Temperature</th>\n",
       "      <th>Air Temperature</th>\n",
       "      <th>Day</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>781974</th>\n",
       "      <td>7.004799</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>7.114755</td>\n",
       "      <td>120.527769</td>\n",
       "      <td>Near Colorless</td>\n",
       "      <td>0.613998</td>\n",
       "      <td>1.758451</td>\n",
       "      <td>0.255472</td>\n",
       "      <td>2.092090</td>\n",
       "      <td>120.745502</td>\n",
       "      <td>241.446886</td>\n",
       "      <td>3.099394</td>\n",
       "      <td>4.469775e-02</td>\n",
       "      <td>257.717511</td>\n",
       "      <td>22.900917</td>\n",
       "      <td>54.310518</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937737</th>\n",
       "      <td>8.299823</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>4.713490</td>\n",
       "      <td>220.284903</td>\n",
       "      <td>Faint Yellow</td>\n",
       "      <td>1.543039</td>\n",
       "      <td>4.341496</td>\n",
       "      <td>0.316341</td>\n",
       "      <td>3.077392</td>\n",
       "      <td>228.707208</td>\n",
       "      <td>282.409585</td>\n",
       "      <td>3.749201</td>\n",
       "      <td>8.410000e-05</td>\n",
       "      <td>92.378364</td>\n",
       "      <td>64.103574</td>\n",
       "      <td>72.016863</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907828</th>\n",
       "      <td>8.077128</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>6.999236</td>\n",
       "      <td>157.332074</td>\n",
       "      <td>Faint Yellow</td>\n",
       "      <td>0.363389</td>\n",
       "      <td>0.537449</td>\n",
       "      <td>0.032343</td>\n",
       "      <td>1.306127</td>\n",
       "      <td>136.219129</td>\n",
       "      <td>214.876158</td>\n",
       "      <td>2.215031</td>\n",
       "      <td>1.954040e-04</td>\n",
       "      <td>187.093504</td>\n",
       "      <td>26.600483</td>\n",
       "      <td>74.400507</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784628</th>\n",
       "      <td>7.813995</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>6.168141</td>\n",
       "      <td>200.820979</td>\n",
       "      <td>Near Colorless</td>\n",
       "      <td>0.731114</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.440061</td>\n",
       "      <td>72.935525</td>\n",
       "      <td>342.590598</td>\n",
       "      <td>3.030572</td>\n",
       "      <td>4.894026e-02</td>\n",
       "      <td>334.951667</td>\n",
       "      <td>16.434954</td>\n",
       "      <td>98.879709</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662460</th>\n",
       "      <td>6.691067</td>\n",
       "      <td>0.506861</td>\n",
       "      <td>8.280426</td>\n",
       "      <td>143.161413</td>\n",
       "      <td>Colorless</td>\n",
       "      <td>0.026614</td>\n",
       "      <td>1.532804</td>\n",
       "      <td>0.161636</td>\n",
       "      <td>2.780277</td>\n",
       "      <td>300.992636</td>\n",
       "      <td>291.962088</td>\n",
       "      <td>3.105734</td>\n",
       "      <td>3.490000e-18</td>\n",
       "      <td>211.253831</td>\n",
       "      <td>12.467716</td>\n",
       "      <td>46.854295</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pH      Iron   Nitrate    Chloride           Color  Turbidity  \\\n",
       "781974  7.004799  0.000006  7.114755  120.527769  Near Colorless   0.613998   \n",
       "937737  8.299823  0.001846  4.713490  220.284903    Faint Yellow   1.543039   \n",
       "907828  8.077128  0.001998  6.999236  157.332074    Faint Yellow   0.363389   \n",
       "784628  7.813995  0.001145  6.168141  200.820979  Near Colorless   0.731114   \n",
       "662460  6.691067  0.506861  8.280426  143.161413       Colorless   0.026614   \n",
       "\n",
       "        Fluoride    Copper      Odor     Sulfate  Conductivity  Chlorine  \\\n",
       "781974  1.758451  0.255472  2.092090  120.745502    241.446886  3.099394   \n",
       "937737  4.341496  0.316341  3.077392  228.707208    282.409585  3.749201   \n",
       "907828  0.537449  0.032343  1.306127  136.219129    214.876158  2.215031   \n",
       "784628  0.073730  0.700787  0.440061   72.935525    342.590598  3.030572   \n",
       "662460  1.532804  0.161636  2.780277  300.992636    291.962088  3.105734   \n",
       "\n",
       "           Manganese  Total Dissolved Solids  Water Temperature  \\\n",
       "781974  4.469775e-02              257.717511          22.900917   \n",
       "937737  8.410000e-05               92.378364          64.103574   \n",
       "907828  1.954040e-04              187.093504          26.600483   \n",
       "784628  4.894026e-02              334.951667          16.434954   \n",
       "662460  3.490000e-18              211.253831          12.467716   \n",
       "\n",
       "        Air Temperature   Day  Potability  \n",
       "781974        54.310518   7.0           0  \n",
       "937737        72.016863   6.0           0  \n",
       "907828        74.400507   6.0           0  \n",
       "784628        98.879709  11.0           0  \n",
       "662460        46.854295  20.0           0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# # Create a SimpleImputer and apply it to the numeric columns\n",
    "imputer = SimpleImputer(strategy='median')  # You can choose a different strategy if needed\n",
    "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need x, y values as numpy arrays\n",
    "X = df.iloc[:, 0:-1].values\n",
    "Y = df.iloc[:, -1].values\n",
    "\n",
    "# X = df.iloc[:, 1:-4].values\n",
    "# Y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.004799273, 6.13e-06, 7.114755278, 120.5277688, 'Near Colorless',\n",
       "       0.613997908, 419408, 0.255472008, 2.092090468, 120.745502,\n",
       "       241.4468855, 3.099393646, 0.044697746, 257.7175114, 22.90091727,\n",
       "       54.31051792, 6], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encode categorical values (1, 2, 3 ... values)\n",
    "le1 = LabelEncoder()\n",
    "X[:, 6] = le1.fit_transform(X[:, 6])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "X[:, 16] = le2.fit_transform(X[:, 16])\n",
    "X[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For a sparse output, all columns should be a numeric or convertible to a numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:846\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    843\u001b[0m     \u001b[39m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[39m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     \u001b[39m# dtype conversion if necessary.\u001b[39;00m\n\u001b[1;32m--> 846\u001b[0m     converted_Xs \u001b[39m=\u001b[39m [\n\u001b[0;32m    847\u001b[0m         check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    848\u001b[0m         \u001b[39mfor\u001b[39;49;00m X \u001b[39min\u001b[39;49;00m Xs\n\u001b[0;32m    849\u001b[0m     ]\n\u001b[0;32m    850\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:847\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    843\u001b[0m     \u001b[39m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[39m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     \u001b[39m# dtype conversion if necessary.\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     converted_Xs \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 847\u001b[0m         check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    848\u001b[0m         \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m Xs\n\u001b[0;32m    849\u001b[0m     ]\n\u001b[0;32m    850\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Near Colorless'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\SLIIT\\Year 03 sem 02\\FDM\\FDM Prj 2\\FDM_Mini_Project\\script.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SLIIT/Year%2003%20sem%2002/FDM/FDM%20Prj%202/FDM_Mini_Project/script.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Column transform categorical columns (0, 1, 0 ...)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SLIIT/Year%2003%20sem%2002/FDM/FDM%20Prj%202/FDM_Mini_Project/script.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ct1 \u001b[39m=\u001b[39m ColumnTransformer(transformers\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mencode\u001b[39m\u001b[39m'\u001b[39m, OneHotEncoder(), [\u001b[39m6\u001b[39m])], remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SLIIT/Year%2003%20sem%2002/FDM/FDM%20Prj%202/FDM_Mini_Project/script.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X \u001b[39m=\u001b[39m ct1\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SLIIT/Year%2003%20sem%2002/FDM/FDM%20Prj%202/FDM_Mini_Project/script.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ct2 \u001b[39m=\u001b[39m ColumnTransformer(transformers\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mencode\u001b[39m\u001b[39m'\u001b[39m, OneHotEncoder(), [\u001b[39m20\u001b[39m])], remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SLIIT/Year%2003%20sem%2002/FDM/FDM%20Prj%202/FDM_Mini_Project/script.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X \u001b[39m=\u001b[39m ct2\u001b[39m.\u001b[39mfit_transform(X)\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:767\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    765\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record_output_indices(Xs)\n\u001b[1;32m--> 767\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hstack(\u001b[39mlist\u001b[39;49m(Xs))\n",
      "File \u001b[1;32mc:\\Users\\ranuja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:851\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    846\u001b[0m         converted_Xs \u001b[39m=\u001b[39m [\n\u001b[0;32m    847\u001b[0m             check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    848\u001b[0m             \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m Xs\n\u001b[0;32m    849\u001b[0m         ]\n\u001b[0;32m    850\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 851\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    852\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFor a sparse output, all columns should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    853\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbe a numeric or convertible to a numeric.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    854\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39mreturn\u001b[39;00m sparse\u001b[39m.\u001b[39mhstack(converted_Xs)\u001b[39m.\u001b[39mtocsr()\n\u001b[0;32m    857\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: For a sparse output, all columns should be a numeric or convertible to a numeric."
     ]
    }
   ],
   "source": [
    "# Column transform categorical columns (0, 1, 0 ...)\n",
    "ct1 = ColumnTransformer(transformers=[('encode', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X = ct1.fit_transform(X)\n",
    "\n",
    "ct2 = ColumnTransformer(transformers=[('encode', OneHotEncoder(), [20])], remainder='passthrough')\n",
    "X = ct2.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, ..., 25.80560754, 4.0, 17.0],\n",
       "       [0.0, 0.0, 0.0, ..., 45.31816114, 16.0, 8.0],\n",
       "       [0.0, 0.0, 0.0, ..., 75.71125799, 16.0, 19.0],\n",
       "       ...,\n",
       "       [0.0, 0.0, 0.0, ..., 60.3323639, 19.0, 8.0],\n",
       "       [0.0, 0.0, 0.0, ..., 45.24376613, 21.0, 21.0],\n",
       "       [0.0, 0.0, 0.0, ..., 36.67733054, 1.0, 7.0]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TRAIN [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.08964742005388752\n",
      " 0.22250950554342272 0.15996135975192427 -0.6381875866222126\n",
      " -0.042288407823216426 -0.8072420424603828 0.06677454259727253\n",
      " 1.3226740845347544 -0.8490761665366783 0.9445235266694276\n",
      " -0.7634630583229903 -0.1073774995704066 -0.46782054283570396\n",
      " -0.20849567405751046 -1.018199837239626 -0.5522348960288287\n",
      " -1.8997789033146155 -1.3448568906243474 0.804588997837725]\n",
      "Y TRAIN [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Normalize input values\n",
    "\n",
    "sc = StandardScaler()  # range: -3 to +3\n",
    "x_train[:, 13:] = sc.fit_transform(x_train[:, 13:])\n",
    "x_test[:, 13:] = sc.transform(x_test[:, 13:])\n",
    "\n",
    "print(\"X TRAIN\", x_train[0])\n",
    "print(\"Y TRAIN\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate recall, accuracy, precision and F1 of trained_RDF_model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 1. 0. 0.]\n",
      "F1 Score: 0.7731525911708254\n",
      "Precision: 0.6480969380059329\n",
      "Recall: 0.9580081753994798\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import precision_score, recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# classifier = joblib.load('trained_RDF_model_3.joblib')\n",
    "\n",
    "# y_pred_rdf = classifier.predict(x_test)\n",
    "# print(y_pred_rdf)\n",
    "\n",
    "# # Assuming y_true contains the true labels and y_pred contains the predicted labels\n",
    "# precision = precision_score(y_test, y_pred_rdf)\n",
    "# recall = recall_score(y_test, y_pred_rdf)\n",
    "# f1 = f1_score(y_test, y_pred_rdf)\n",
    "\n",
    "# print(\"F1 Score:\", f1)\n",
    "\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Logistic Regression classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_classifier = LogisticRegression(random_state=0)\n",
    "# lr_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(lr_classifier, 'trained_LR_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_lr = lr_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=2)\n",
    "# print(np.concatenate([y_pred_lr.reshape(len(y_pred_lr), 1), y_test.reshape(len(y_test), 1)], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confMatrix = confusion_matrix(y_test, y_pred_lr)\n",
    "# print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_model_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "# print(lr_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Support Vector Machine classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector classifier\n",
    "# svm_classifier = SVC(kernel='linear', random_state=0)  # default is rbf\n",
    "# svm_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(svm_classifier, 'trained_SVM_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_svm = svm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confMatrix = confusion_matrix(y_test, y_pred_svm)\n",
    "# print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "# print(svm_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the K-Nearest Neighbour classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # classic euclidean distance\n",
    "# knn_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(knn_classifier, 'trained_KNN_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_knn = knn_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "# print(knn_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the decision tree classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dtree_classifier = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "# dtree_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(dtree_classifier, 'trained_DTR_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_dtree = dtree_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtc_model_accuracy = accuracy_score(y_test, y_pred_dtree)\n",
    "# print(dtc_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the random forest classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_classifier = RandomForestClassifier(n_estimators = 100, criterion='entropy', random_state = 0)\n",
    "rfc_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "joblib.dump(rfc_classifier, 'trained_RDF_model_4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rdf = rfc_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model_accuracy = accuracy_score(y_test, y_pred_rdf)\n",
    "print(rfc_model_accuracy)\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "# remove missing values - 0.8642686209991026\n",
    "# remove missing of categorical and replace others with median - 0.87615241140421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = [7.66857169, 7.06e-08, 7.541255359, 198.1312335, 1.31e-95,\n",
    "#        0.767179279, 'Colorless', 0.137766996, 1.008886456, 2.391833449,\n",
    "#        0.750761234, 148.9474344, 242.7039915, 3.709734571, 2.301398715,\n",
    "#        100.9851033, 'Stream', 9.674425593, 35.25315137, 12.0, 1.0]\n",
    "\n",
    "classifier = joblib.load('trained_RDF_model_3.joblib')\n",
    "values = [1, 7.06e-08, 7.541255359, 198.1312335, 1.31e-95,\n",
    "       0.767179279, 'Colorless', 0.137766996, 1.008886456, 2.391833449,\n",
    "       0.750761234, 148.9474344, 242.7039915, 3.709734571, 2.301398715,\n",
    "       100.9851033, 'Stream', 9.674425593, 35.25315137, 12.0, 1.0]\n",
    "\n",
    "# Convert the input values to a DataFrame\n",
    "input_data = pd.DataFrame([values])\n",
    "\n",
    "# Preprocess the input data\n",
    "input_data = input_data.values  # Convert to NumPy array\n",
    "\n",
    "# label encode the values\n",
    "input_data[:, 6] = le1.transform(input_data[:, 6])\n",
    "input_data[:, 16] = le2.transform(input_data[:, 16])\n",
    "\n",
    "# column transform the values\n",
    "input_data = ct1.transform(input_data)\n",
    "input_data = ct2.transform(input_data)\n",
    "\n",
    "# scale the values\n",
    "input_data[:, 13:] = sc.transform(input_data[:, 13:])\n",
    "\n",
    "# print(input_data)\n",
    "\n",
    "y_single = classifier.predict(input_data)\n",
    "\n",
    "print(y_single[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_single = rfc_classifier.predict(input_data)\n",
    "\n",
    "# print(y_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    classifier, x_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Examples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training Accuracy\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Test Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ACCURACY SCORES OF EACH MODEL\\n\")\n",
    "\n",
    "# print(\"Logistic Regression Classifier\\t\", round(lr_model_accuracy * 100, 2))\n",
    "# print(\"SVM Classifier\\t\\t\\t\", round(svm_model_accuracy * 100, 2))\n",
    "# print(\"K-NN Classifier\\t\\t\\t\", round(knn_model_accuracy * 100, 2))\n",
    "# print(\"Decision Tree Classifier\\t\", round(dtc_model_accuracy * 100, 2))\n",
    "# print(\"Random Forest Classifier\\t\", round(rfc_model_accuracy * 100, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
